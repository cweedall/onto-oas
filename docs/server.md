# Generating the server

OBA uses [OpenAPI Generator](https://github.com/OpenAPITools/openapi-generator#overview) to generate the server.

## OpenAPI Generator

OpenAPI Generator allows generation of API client libraries (SDK generation), server stubs, documentation and 
configuration automatically given an OpenAPI Spec (both 2.0 and 3.0 are supported). The OpenAPI Generator website
maintains a list of languages/frameworks are supported.

### Integration with RDF

The OpenAPI Generator easily provide an API backend for mocking based on the OpenAPI Specification. However, it does not
provide the logic of the server (For example, a database connection).

OBA modifies the server generated by OpenAPI Generator using [templates](https://github.com/OpenAPITools/openapi-generator/blob/master/docs/templating.md).
As result, the server can:

 1. Connect and query resources from the SPARQL endpoint.
    - Convert the RDF triples to JSON (using JSON/LD).
 2. Connect and insert resources to the SPARQL endpoint.
    - Convert the JSON to RDF triples (using JSON/LD).
    
### Generating the JSON/LD context

Since the adoption of JSON/LD is in progress, OBA can convert the format of the responses from JSON/LD to JSON.
To do that, OBA requires a file with the context. Simply speaking, a context is used to map terms to IRIs. 

!!! info 
    Visit the [JSON/LD documentation](https://json-ld.org/spec/latest/json-ld/#the-context) for more information

Currently, OBA does not support the generation of the context file. 
We recommend to use the project [owl2jsonld](https://github.com/sirspock/owl2jsonld)

!!! info
    This package is a fork of [owl2jsonld](https://github.com/stain/owl2jsonld). Thanks Stain!

#### One ontology

If you are using one ontologies.

```bash
java -jar owl2jsonld-0.3.0-SNAPSHOT-standalone.jar  \
    $ONTOLOGY_URL > server/context.json
```

For example, the Model Catalog ontology:

```bash
java -jar owl2jsonld-0.3.0-SNAPSHOT-standalone.jar  \
    https://mintproject.github.io/Mint-ModelCatalog-Ontology/release/1.2.0/ontology.xml > server/context.json
```

#### Two or more ontologies

To merge the multiple JSON files, you can install the [jq](https://stedolan.github.io/jq/)

```bash

java -jar owl2jsonld-0.3.0-SNAPSHOT-standalone.jar  \
    $ONTOLOGY_URL1 > a.json
java -jar owl2jsonld-0.3.0-SNAPSHOT-standalone.jar \
    $ONTOLOGY_URL2 > b.json    
jq -s '.[0] * .[1]' a.json b.json  | jq -S > context.json
rm a.json b.json

```

For example, the Model Catalog ontology:

```bash

java -jar owl2jsonld-0.3.0-SNAPSHOT-standalone.jar  \
    https://mintproject.github.io/Mint-ModelCatalog-Ontology/release/1.2.0/ontology.xml > a.json
java -jar owl2jsonld-0.3.0-SNAPSHOT-standalone.jar \
    https://knowledgecaptureanddiscovery.github.io/SoftwareDescriptionOntology/release/1.2.0/ontology.xml > b.json
jq -s '.[0] * .[1]' a.json b.json  | jq -S > context.json
rm a.json b.json

```

    
## Generating the server

Currently, the following languages/frameworks are supported by OBA:

- Python/flash

### Copying the files

First, you must copy the context file and OpenAPI specification

```bash
mv context.json openapi.yaml python/
```

### How to generate it?

!!! warning
    You must install Docker.

Change the directory the server implementation 

```bash
$ cd python
```

 
Run the OpenAPI generator script to generate the server

```bash
$ bash generate-server.sh
...
...
SUCCESS
```

#### Structure of the server

The server directory contains the following files and directories

```bash
$ ls server/
Dockerfile: A Dockerfile to build the Docker Images
README.md: A README.md with the instructions to run the server
contexts: The directory with the JSON/LD contests
openapi_server: The server implemenation
queries: The directory with the SPARQL queries
requirements.txt: The Python requirements of the server 
test-requirements.txt: The Python requirements of testing the server 
```


